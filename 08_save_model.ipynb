{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d8548bc",
   "metadata": {},
   "source": [
    "# №8. Сохранение и загрузка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6614a744",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071919ca",
   "metadata": {},
   "source": [
    "## 1. Сохранение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d9efa8",
   "metadata": {},
   "source": [
    "**Примечания**:\n",
    "- Не стоит сохранять модель в \"лоб\" `torch.save(my_model, path)`, так как при смене версии Python\\ОС могут возникнуть сложности и ошибки при загрузке.\n",
    "- Лучше всего сохранять ***состояние модели***, т.е. `torch.save(my_model.state_dict(), path)`.\n",
    "- Можно сохранять любую необходимую информацию, например:\n",
    "    * Текущие состояния `optim`, `lr_scheduler`, `loss_model`;\n",
    "    * Изменения `lr`, `loss`, `acc` и прочих параметров и метрик;\n",
    "    * Информация о эпохе (всего запланировано, сколько пройдено, когда сохранялись модели)\n",
    "    * Код создания модели;\n",
    "    * *И много другой информации*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd649e7",
   "metadata": {},
   "source": [
    "Пример словаря-чекпоинта для сохранения:\n",
    "```python\n",
    "checkpoint = {\n",
    "    'info': str_info,\n",
    "    'state_model': model.state_dict(),\n",
    "    'state_opt': opt.state_dict(),\n",
    "    'state_lr_scheduler': lr_scheduler.state_dict(),\n",
    "    'loss': {\n",
    "        'train_loss': train_loss,\n",
    "        'val_loss': val_loss,\n",
    "        'best_loss': best_loss\n",
    "    },\n",
    "    'metric': {\n",
    "        'train_acc': train_acc,\n",
    "        'val_acc': val_acc,\n",
    "    },\n",
    "    'lr': lr_list,\n",
    "    'epoch': {\n",
    "        'EPOCHS': EPOCHS,\n",
    "        'save_epoch': save_epoch\n",
    "    }\n",
    "}\n",
    "torch.save(checkpoint, 'model_state_dict_01_01_24.pt')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848c5ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Класс для управления обучением\n",
    "class TrainingTracker:\n",
    "    def __init__(self, experiment_name, save_dir='./checkpoints'):\n",
    "        self.experiment_name = experiment_name\n",
    "        self.save_dir = Path(save_dir)\n",
    "        self.save_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        self.history = {\n",
    "            'train_loss': [], 'val_loss': [],\n",
    "            'train_acc': [], 'val_acc': [],\n",
    "            'learning_rates': [],\n",
    "            'epoch_times': [],\n",
    "            'grad_norms': []\n",
    "        }\n",
    "        \n",
    "        self.best_metrics = {\n",
    "            'best_loss': float('inf'),\n",
    "            'best_accuracy': 0.0,\n",
    "            'best_epoch': 0\n",
    "        }\n",
    "    \n",
    "    def update_epoch(self, epoch, train_loss, val_loss, train_acc, val_acc, lr, epoch_time, grad_norm=None):\n",
    "        self.history['train_loss'].append(train_loss)\n",
    "        self.history['val_loss'].append(val_loss)\n",
    "        self.history['train_acc'].append(train_acc)\n",
    "        self.history['val_acc'].append(val_acc)\n",
    "        self.history['learning_rates'].append(lr)\n",
    "        self.history['epoch_times'].append(epoch_time)\n",
    "        \n",
    "        if grad_norm:\n",
    "            self.history['grad_norms'].append(grad_norm)\n",
    "        \n",
    "        # Обновляем лучшие метрики\n",
    "        if val_acc > self.best_metrics['best_accuracy']:\n",
    "            self.best_metrics.update({\n",
    "                'best_accuracy': val_acc,\n",
    "                'best_epoch': epoch,\n",
    "                'best_loss': val_loss\n",
    "            })\n",
    "    \n",
    "    def save_checkpoint(self, model, optimizer, scheduler, epoch, config):\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state': model.state_dict(),\n",
    "            'optimizer_state': optimizer.state_dict(),\n",
    "            'scheduler_state': scheduler.state_dict() if scheduler else None,\n",
    "            'tracker_history': self.history,\n",
    "            'best_metrics': self.best_metrics,\n",
    "            'config': config,\n",
    "            'timestamp': datetime.datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        filename = self.save_dir / f\"{self.experiment_name}_epoch_{epoch}.pt\"\n",
    "        torch.save(checkpoint, filename)\n",
    "        \n",
    "        # Сохраняем также как best если это лучшая модель\n",
    "        if epoch == self.best_metrics['best_epoch']:\n",
    "            best_filename = self.save_dir / f\"{self.experiment_name}_best.pt\"\n",
    "            torch.save(checkpoint, best_filename)\n",
    "        \n",
    "        # Сохраняем историю в JSON для анализа\n",
    "        self.save_history_json()\n",
    "    \n",
    "    def save_history_json(self):\n",
    "        history_file = self.save_dir / f\"{self.experiment_name}_history.json\"\n",
    "        with open(history_file, 'w') as f:\n",
    "            json.dump(self.history, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9343111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Использование в тренировочном цикле\n",
    "def train_model(model, train_loader, val_loader, config):\n",
    "    tracker = TrainingTracker(config['experiment_name'])\n",
    "    \n",
    "    for epoch in range(config['epochs']):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Тренировка\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, optimizer, scheduler)\n",
    "        \n",
    "        # Валидация\n",
    "        val_loss, val_acc = validate_epoch(model, val_loader)\n",
    "        \n",
    "        # Расчет времени и градиентов\n",
    "        epoch_time = time.time() - start_time\n",
    "        current_lr = get_current_lr(optimizer)\n",
    "        \n",
    "        # Обновление трекера\n",
    "        tracker.update_epoch(\n",
    "            epoch, train_loss, val_loss, train_acc, val_acc, \n",
    "            current_lr, epoch_time\n",
    "        )\n",
    "        \n",
    "        # Сохранение чекпоинта\n",
    "        if epoch % config['save_every'] == 0:\n",
    "            tracker.save_checkpoint(model, optimizer, scheduler, epoch, config)\n",
    "        \n",
    "        # Логирование\n",
    "        print(f\"Epoch {epoch}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "    \n",
    "    return tracker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26361b42",
   "metadata": {},
   "source": [
    "## 2. Загрузка"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435e118c",
   "metadata": {},
   "source": [
    "**Примечание**:\n",
    "\n",
    "- Обратить внимание на то, где хранилась модель и прочие данные во время сохранения: если модель хранилась на `cuda`, то при ее сохранении и последущей загрузке она сразу же будет автоматически пытаться загрузиться на `cuda`. Если `cuda` будет недоступна, то получим ошибку:\n",
    "```\n",
    "RuntimeError: Attempting to deserialize object on a CUDA devivce but torch.cuda.is_available() is False. ...\n",
    "```\n",
    "\n",
    "- Для избежания ошибки следует загружать данные с указанием параметра `map_location`:\n",
    "```python\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "param_model = torch.load('path/to/model', map_location=device)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a35a255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(filepath, model, optimizer=None, scheduler=None, device='cuda'):\n",
    "    \"\"\"\n",
    "    Загрузка checkpoint и восстановление состояния\n",
    "    \"\"\"\n",
    "    checkpoint = torch.load(filepath, map_location=device)\n",
    "    \n",
    "    # Загрузка модели\n",
    "    if 'state_model' in checkpoint:\n",
    "        model.load_state_dict(checkpoint['state_model'])\n",
    "    elif 'model_state' in checkpoint:\n",
    "        model.load_state_dict(checkpoint['model_state'])\n",
    "    elif 'model' in checkpoint:\n",
    "        model.load_state_dict(checkpoint['model'])\n",
    "    \n",
    "    # Загрузка оптимизатора\n",
    "    if optimizer and 'state_opt' in checkpoint:\n",
    "        optimizer.load_state_dict(checkpoint['state_opt'])\n",
    "    elif optimizer and 'optimizer_state' in checkpoint:\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state'])\n",
    "    \n",
    "    # Загрузка scheduler\n",
    "    if scheduler and 'state_lr_scheduler' in checkpoint:\n",
    "        scheduler.load_state_dict(checkpoint['state_lr_scheduler'])\n",
    "    elif scheduler and 'scheduler_state' in checkpoint:\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state'])\n",
    "    \n",
    "    print(f\"Checkpoint loaded from {filepath}\")\n",
    "    print(f\"Epoch: {checkpoint.get('epoch', 'N/A')}\")\n",
    "    \n",
    "    return checkpoint\n",
    "\n",
    "# Использование\n",
    "model = YourModel()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10)\n",
    "\n",
    "checkpoint = load_checkpoint(\n",
    "    'model_state_dict_01_01_24.pt', \n",
    "    model, optimizer, scheduler\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
